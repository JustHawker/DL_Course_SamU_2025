# Курс "Глубокое обучение в задачах технического зрения и предиктивной диагностики" Самарского университета  

_Курс разработан Центром интеллектуальной мобильности многофункциональных беспилотных авиационных систем (БАС) при поддержке Аналитизческим Центром при Правительстве РФ._

### Курс ведут
Лектор:

[Артем Владимирович Никоноров](https://ssau.ru/staff/66320001-nikonorov-artem-vladimirovich), д.т.н.\
✉️ artniko[at]gmail.com

Ассистенты:

[Макаров Андрей Романович](https://ssau.ru/staff/702140902-makarov-andrey-romanovich/edu)\
✉️ makarov.ar[at]ssau.ru

[Ульянов Дмитрий Иванович](https://ssau.ru/staff/441332316-ulyanov-dmitriy-ivanovich/edu)\
✉️ neulyanodmitry[at]gmail.com
           
### Ссылки на материалы курса
[Телеграмм группа](https://t.me/+xfiOdqTGoLY2YzAy)

[Сводная таблица](https://docs.google.com/spreadsheets/d/1Zd9Q-EYVqNU6ToEELEzlcBIz-SAPjwi8hbtwS3NAyNc/edit?gid=852261837#gid=852261837)

**Материалы за прошлые годы:**
* [2020-21](https://github.com/da0c/DL_Course_SamU)
* [2022-23](https://github.com/kvvik/DL_Course_SamU)
* [2023-24](https://github.com/andremakar/DL_Course_SamU)

### Использованные при разработке курсы
Курс основывается на предыдущих более обзорных лекциях и туториалах по глубокому обучению и его приложениях, в частности, вот [небольшая обзорная лекция](https://youtu.be/Gpq1PFUee88) в Кавказском Математическом Центре. Также во многом этот курс является адаптацией известнейшего курса http://cs231n.stanford.edu/  

<!-- Ранее прочитанные лекции курсов "Нейронные сети и глубокое обучение".  
Материалы курса за 2020-21 годы расположены [здесь](https://github.com/da0c/DL_Course_SamU).
Материалы курса за 2022-23 годы расположены [здесь](https://github.com/kvvik/DL_Course_SamU)
Материалы курса за 2023-24 годы расположены [здесь](https://github.com/andremakar/DL_Course_SamU) -->

## Структура курса

1. **Введение в глубокое обучение**
   - Краткий обзор всех достижений машинного обучения до сверточных нейронных сетей. 2 лекции.
3. **Основы глубокого обучения**
   - Основной материал курса. ~8 лекций
4. **Дополнительные главы глубокого обучения**
   - Новинки и SOTA (State Of The Art) решения, трансформеры, метаобучение, zero shot learning и др.
   
<!--Курс 25 года состоит из трех частей:  
**Введение в глубокое обучение:** краткий обзор всех достижений машинного обучения до сверточных нейронных сетей, две лекции.  
**Основы глубокого обучения:** собственно основной материал курса, порядка 8 лекций.  
**Дополнительные главы глубокого обучения:** новинки и SOTA решения, трансформеры, метаобучение, zero shot learning и другое.  -->

## Расписание
<!--**Видеозаписи лекций 2020-21 годов  можно найти по [ссылке](https://github.com/da0c/DL_Course_SamU).**-->

> [!IMPORTANT]
> <ins>**ОБНОВЛЕНО**</ins> Первая лекция запланирована на 21 февраля, в 18:45 по смр.

## План лекций 

### **1. Вводные лекции, в том числе для самостоятельного изучения.**   
  
**Лекции 1-2. Введение в искусственные нейронные сети.**   

* Введение в курс и краткая история вопроса.  
* Примеры решения задач на базе искусственных нейронных сетей.   
* Подходы основанные на данных.  
* Задачи технического зрения и предиктивной диагностики БАС.  
* **Дополнительный материал:** Основные идеи - От MLP до CNN.  

[Видеозапись первой части](https://youtu.be/pruCadZdhmQ)  
[Видеозапись второй части](https://youtu.be/bsdpRfQM-O8)  
[Презентация к лекциям 1-2](https://github.com/kvvik/DL_Course_SamU/blob/master/lections/Nikonorov-2023.pdf)    



### **2. Основы глубокого обучения.**   
  
**Лекция 3. Основы построения и применения искусственных нейронных сетей. Математическая формализация нейросетевого подхода.**  

* Мультиклассовый SVM и его функция потерь.  
* Софтмакс и мультимодальная логистическая регрессия.  
* Оптимизация функции потерь.  
* Стохастический градиентный спуск (SGD).  
* Разбор задач к самостоятельной: функции потерь для SVM и софтмакса.  

[Видеозапись третьей лекции](https://youtu.be/9nUzJxCeKIc)  
[Презентация к лекции 3](https://github.com/kvvik/DL_Course_SamU/blob/master/Lectures/Lecture_3_SGD_22.pdf)  
[Python-ноутбук к лекции 3](https://github.com/kvvik/DL_Course_SamU/blob/master/Lectures/Lecture_3.ipynb)  

**Лекция 4. Обучение нейронных сетей на основе обратного распространения ошибки.**  
 
* Классификация с точки зрения нейронной сети.  
* Многослойный перцептрон.  
* Представление сети в виде вычислительного графа.
* Алгоритм обратного распространения ошибки на вычислительном графе.  
* Разбор задач к самостоятельной: прямое и обратное распротранение по вычислительному графу.  

[Видеозапись четвертой лекции, первая часть](https://youtu.be/Zx6YggTqTJs)  
[Видеозапись четвертой лекции, вторая часть](https://youtu.be/h4mE1AhLvAI)  

[Презентация к лекции 4](https://github.com/kvvik/DL_Course_SamU/blob/master/Lectures/lecture_4_BP_22.pdf)  

**Лекция 5. Сверточные нейронные сети (СНС).**  
* История.  
* Основные операции СНС.  
* Применение СНС для решения задач технического зрения и предиктивной диагностики БАС.  
* Применение СНС вне задач машинного зрения.  
* Разбор задач к самостоятельной: расчет выхода сверточной сети.

[Презентация к лекции 5](https://github.com/kvvik/DL_Course_SamU/blob/master/Lectures/Lecture_5_CNN_22.pdf)  
  
**Лекция 6. Инструментарий глубокого обучения.**  
* CPU vs GPU vs TPU.  
* Пакеты глубокого обучения, Tensorflow, Keras и другие.  
* Вычислительные графы СНС.

[Видеозапись шестой лекции](https://youtu.be/vSwXdsuDN9A)  
    
[Презентация к лекции 6](https://github.com/kvvik/DL_Course_SamU/blob/master/Lectures/lecture_6_DL_Tools_22.pdf) 

**Самостоятельня работа.**  
  
**3 задачи** из лекций 2-5.
> [!IMPORTANT]
> Участие в самостоятельной, как и сдача лабораторных, является **_необходимым условием_** для допуска к экзамену 

**Лекция 7.1. Обучение СНС, часть 1.**  

* Активационные функции, обработка данных сетью.  
* Пакетная нормализация и другие трюки.  
* Transfer learning.
   
**Лекция 7.2. Обучение СНС, часть 2.**  

* Политики обновления гиперпараметров.  
* Тюнинг процесса обучения.
* Вопросы регуляризации и аугментации данных.

[Видеозапись седьмой лекции](https://youtu.be/g0iMdzk5Q-k)  
  
[Презентация к лекции 7](https://github.com/kvvik/DL_Course_SamU/blob/master/Lectures/lecture_7_Training1_22.pdf)  

**Лекция 8. Базовые архитектуры СНС**  

* Базовые архитектуры - AlexNet, VGG, GoogleNet, ResNet, UNET и другие. 
* Основные архитектуры для решения задач технического зрения и предиктивной аналитики БАС.  

[Видеозапись восьмой лекции](https://youtu.be/X77_BhagkJ0)  
  
[Презентация к лекции 8](https://github.com/kvvik/DL_Course_SamU/blob/master/Lectures/lecture_8_Training2_22.pdf)    

### **3. Дополнительные главы**

**Лекция 9. Трансформерные архитектуры**  

* Сети-трансформеры.  
* Механизм внимания.  
* ViT-модели.  
* Применение в задачах технического зрения, анализа видео, интеллектуальной эксплуатации технических систем в том числе БАС.

[Видеозапись девятой лекции](https://youtu.be/ihkqOdUQsmo)  
  
[Презентация к лекции 9](https://github.com/kvvik/DL_Course_SamU/blob/master/Lectures/lecture_9_Arch_22.pdf)  

**Самостоятельное изучение**  
  
**Лекция 10. Генеративные и рекуррентные модели**  

* RNN/LSTM.  
* Механизм attention.
* Обработка естественного языка.
* GAN сети и другие генеративные порходы.  
* Детектирование и сегментация.

[Видеозапись десятой лекции](https://youtu.be/LjZxH6jGk-E)  
  
[Презентация к лекции 10](https://github.com/kvvik/DL_Course_SamU/blob/master/Lectures/lecture_10_Transfomers_22.pdf)

**Лекция 11. SOTA модели**  

* Zero shot подходы.  
* Метаобучение.  
* Федеративное обучение. 
* Диффузные модели и мосты Шредингера.

## План лабораторных работ

Списки групп и статус выполнения лабораторных работ можно найти в [гугл-таблице](https://docs.google.com/spreadsheets/d/1Zd9Q-EYVqNU6ToEELEzlcBIz-SAPjwi8hbtwS3NAyNc/edit?gid=852261837#gid=852261837). 

## Литература и дополнительные источники для самостоятельного изучения    

1. Отличная книга на русском по глубокому обучению -  
[С. И. Николенко, А. Кадурин, Е. В. Архангельская, Глубокое обучение. Погружение в мир нейронных сетей. 2018](https://www.ozon.ru/context/detail/id/154415719/)  
2. Отличная книга по техническим аспектам реализации на Python -  
[Шолле Франсуа, Глубокое обучение на Python](https://www.ozon.ru/context/detail/id/145615583/)  

3. Хорошая современная книга на английском: [Advanced Deep Learning with Python. By Ivan Vasilev](http://neuralnetworksanddeeplearning.com)

4. [Лекционный курс К.В. Воронцова по машинному обучению](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%28%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%2C_%D0%9A.%D0%92.%D0%92%D0%BE%D1%80%D0%BE%D0%BD%D1%86%D0%BE%D0%B2%29).  

5. [Видеолекция академика Ю.И. Журавлева](https://www.youtube.com/watch?v=R3CMqrrIWOk) об истоках машинного обучения в СССР и о сочетании эвристики и науки в распознавании образов.  
7. Видеолекции С.И. Николенко по GAN сетям [1](https://www.youtube.com/watch?v=SlJgPIOlpiI), [2](https://www.youtube.com/watch?v=w38m5mTrG_M&t=1147s).
Хорошая проверка ваших знаний, на выходе из настоящего курса вы должны полностью понимать то, что говорится в этих лекциях по GAN.  
  
8. Хорошая вводная книга по питону и базовым библиотекам, таким как numpy, pandas, jupyter.
[Python и анализ данных. Второе издание [2020] Уэс Маккинни](https://www.ozon.ru/product/python-i-analiz-dannyh-vtoroe-izdanie-makkini-ues-285933371)  
[Альтернативная ссылка](https://vk.com/wall-51126445_67509)  
Важное замечание: первое издание книги содержит в себе короткое введение в python, изъятое из второго издания. Первое издание с руководством по питону можно найти [например здесь](https://t.me/physics_lib).

9. Решение задач технического зрения для БАС, [трекинг БАС](https://github.com/jingliinpurdue/Fast-and-Robust-UAV-to-UAV-Detection-and-Tracking)  

## Подборка книг по математике, базовых для машинного обучения, для самостоятельного изучения    
По многочисленным просьбам привожу список книг по направлениям математики, которые составляют базу для машинного и глубокого обучения.  
Базу составляют - матанализ,  линейная алгебра, методы оптимизации, теория вероятностей и математическая статистика.  
Опционально, но полезно, знать цифровую обработку сигналов и теорию случайных процессов, численные методы, и конечно обработку изображений.  

1. Матанализ: Г. М. ФИХТЕНГОЛЬЦ. ОСНОВЫ. МАТЕМАТИЧЕСКОГО. АНАЛИЗА.
2. Линейная алгебра: Г.С. Швецов, Линейная алгебра. теория и прикладные аспекты.
3. Альтернативный, всегда актуальный вариант - Гантмахер, Теория матриц.
4. Методы оптимизации - Советская книга по методам оптимизации в технических задачах. Для тех кто не знает как рашифровывается BFGS))) -  
[Реклейтис Г., Рейвиндран А., Рэгсдел К. Оптимизация в технике. Том 1 М.: Мир, 1986. – 348 с.](https://www.studmed.ru/rekleytis-g-reyvindran-a-regsdel-k-optimizaciya-v-tehnike-tom-1_5d310297b68.html)  
5. Тервер и матстат: Гмурман В.Е., Теория вероятностей и математическая статистика.
6. Обработка изображений, здесь можно привести целый список, немного классических книг: Э. Прэтт, Цифровая обработка изображений; Гонсалес Р., Вудс Р. Цифровая обработка изображений;
7. Ну и важная тема, формирование и восприятие цвета: М. Домасев, С. Гнатюк, Цвет, управление цветом, цветовые расчеты и измерения  


[Хороший телеграмм канал с подборкой технических книг](https://t.me/physics_lib)  



